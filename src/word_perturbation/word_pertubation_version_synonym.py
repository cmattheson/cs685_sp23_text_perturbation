# -*- coding: utf-8 -*-
"""word_pertubation_version1.0.1

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mrGu6z5Sl7-Vglpb5fiZJpBedpKxJwAI
"""

import nltk

nltk.download('wordnet', quiet=True)
nltk.download('punkt', quiet=True)
nltk.download('averaged_perceptron_tagger', quiet=True)

from random import randint, seed
from nltk.corpus import wordnet


seed(1)


# --------------------------------------------------------------------------------------------------------------------

def return_random_number(begin, end):
    return randint(begin, end)


class Synonym:

    def __init__(self, first_word, second_word):
        self.first_word = first_word
        self.second_word = second_word


# This is the main function wich needs to be called. Will take string as input and gives pertub string as output.
# s = string and i is dividing the string length for maximum words so lesser the value of i lesser will be pertubation will occur. Note i value should be between (0-1)
def sentence_pertube(s, i, verbose=False):
    max_replace = int(len(s.split()) * i)

    num_perturbed_samples = 0

    if (verbose):
        print(s)


    sample_text = s
    # sample_label = row[1]
    sample_tokenized = nltk.word_tokenize(sample_text)
    sample_pos_tag = nltk.pos_tag(sample_tokenized)

    word_replaced = False
    perturbed_sample = sample_text

    candidate_synonym = []
    can_be_replaced_list = []

    for i in range(0, len(sample_pos_tag)):
        if (sample_pos_tag[i][1] in ('CD', 'JJ', 'JJR', 'JJS', 'NN', 'NNS', 'RB', 'RBR',
                                     'RBS')):  # ----- Replace the word if it is a noun, adjective, or adverb
            for syn in wordnet.synsets(sample_pos_tag[i][0]):
                for l in syn.lemmas():
                    if (sample_pos_tag[i][0] != l.name()):
                        temp_synonym = Synonym(sample_pos_tag[i][0], l.name())
                        candidate_synonym.append(temp_synonym)
                        if (sample_pos_tag[i][0] not in can_be_replaced_list):
                            can_be_replaced_list.append(sample_pos_tag[i][0])

    # max_replace = int(len(can_be_replaced_list)*i)
    if (len(candidate_synonym) > 0):
        # print('Words that can be replaced:', can_be_replaced_list)

        unique_words = len(can_be_replaced_list)
        num_perturbed_words = 0

        index = 0
        while (num_perturbed_words < max_replace and num_perturbed_words < unique_words):

            possible_replacement = []

            for i in range(0, len(candidate_synonym)):
                if (candidate_synonym[i].first_word == can_be_replaced_list[index] or candidate_synonym[
                    i].second_word == can_be_replaced_list[index]):
                    possible_replacement.append(candidate_synonym[i])

            random_candidate = return_random_number(0, len(possible_replacement) - 1)

            original_word = ''
            new_word = ''
            if (possible_replacement[random_candidate].first_word == can_be_replaced_list[index]):
                original_word = possible_replacement[random_candidate].first_word
                new_word = possible_replacement[random_candidate].second_word
            elif (possible_replacement[random_candidate].second_word == can_be_replaced_list[index]):
                original_word = possible_replacement[random_candidate].second_word
                new_word = possible_replacement[random_candidate].first_word

            # print(original_word, 'is replaced by', new_word)

            perturbed_sample_tokenized = nltk.word_tokenize(perturbed_sample)
            replacement_position = -1
            for i in range(0, len(perturbed_sample_tokenized)):
                if (original_word == perturbed_sample_tokenized[i]):
                    replacement_position = i

            if (replacement_position > -1):
                perturbed_sample = ""
                for i in range(0, replacement_position):
                    # replace the words before the replaced word with the original words
                    perturbed_sample += perturbed_sample_tokenized[i] + ' '
                # replace the replaced word with the new word
                perturbed_sample += new_word + ' '
                for i in range(replacement_position + 1, len(perturbed_sample_tokenized)):
                    # replace the remaining words with the original words
                    perturbed_sample += perturbed_sample_tokenized[i] + ' '

                word_replaced = True
                num_perturbed_words += 1

            index += 1

    elif verbose and len(candidate_synonym) == 0:
        print('No word was replaced.')

    if (word_replaced == True):
        num_perturbed_samples += 1

    if perturbed_sample:
        return perturbed_sample
    else:
        # return the original string if we didn't get a perturbed sample: necessary to ensure we don't get a NoneType error
        return s


if __name__ == '__main__':
    s = "friend lent dvd got director festival think went warned technical aspects movie bit shaky writing good great maybe colored judgment admit liked moviethe standouts actors youssef kerkor really good ernie main character kind pathetic likable way adam jones also directed justin lane excellent roommates drive ernie mad bill character justin lane spends lot film dressed like panda far favorite seemed least onedimensional reminded old college roommate much called guy watching dvd really kind lovable funny acting good soso none bad also really liked vigilante duo ridiculous funnyim giving one high marks even though issues tell watch people cared decided make movie way well done adam jones crew"
    print('original sentence:', s)
    print('perturbed sentence:', sentence_pertube(s, 1))

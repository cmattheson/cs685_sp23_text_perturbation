# -*- coding: utf-8 -*-
"""word_pertubation_version1.0

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mrGu6z5Sl7-Vglpb5fiZJpBedpKxJwAI
"""



import nltk
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
from nltk.stem.snowball import SnowballStemmer
from nltk.stem.wordnet import WordNetLemmatizer
nltk.download('wordnet')

from builtins import str

import csv
import sys, getopt

import xml.etree.ElementTree as ET
from xml.dom.minidom import parse, Node
import xml.dom.minidom 
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')      
from numpy import double

from random import seed
from random import randint

from nltk.corpus import wordnet
import random

seed(1)

#--------------------------------------------------------------------------------------------------------------------

def return_random_number(begin, end):
  return randint(begin, end)


class Synonym:
    
   def __init__(self, first_word, second_word):
    self.first_word = first_word
    self.second_word = second_word





#This is the main function wich needs to be called. Will take string as input and gives pertub string as output.
# s = string and i is dividing the string length for maximum words so lesser the value of i lesser will be pertubation will occur. Note i value should be between (0-1)
def sentence_pertube(s,i):
  max_replace = int(len(s.split())*i)
  
  


  num_perturbed_samples = 0
      

  
  print(s)

  is_sample_perturbed = False
  
  sample_text = s
  # sample_label = row[1]
  sample_tokenized = nltk.word_tokenize(sample_text)
  sample_pos_tag = nltk.pos_tag(sample_tokenized)

  word_replaced = False
  perturbed_sample = sample_text
  
  candidate_synonym = []
  can_be_replaced_list = []
    
  for i in range(0, len(sample_pos_tag)):
    if (sample_pos_tag[i][1] in ('CD', 'JJ', 'JJR', 'JJS', 'NN', 'NNS', 'RB', 'RBR', 'RBS')): #----- Replace the word if it is a noun, adjective, or adverb
      for syn in wordnet.synsets(sample_pos_tag[i][0]):
        for l in syn.lemmas():
          if (sample_pos_tag[i][0] != l.name()):
            temp_synonym = Synonym(sample_pos_tag[i][0], l.name())
            candidate_synonym.append(temp_synonym)
            if (sample_pos_tag[i][0] not in can_be_replaced_list):
              can_be_replaced_list.append(sample_pos_tag[i][0])
    
            
  if (len(candidate_synonym) > 0):
    # print('Words that can be replaced:', can_be_replaced_list)
    
    unique_words = len(can_be_replaced_list)
    num_perturbed_words = 0
    
    
    

    
    # index = random.randint(0, (len(s.split()) - 1)//5)
    while (num_perturbed_words < max_replace and num_perturbed_words < unique_words):
      index = random.randint(0, (len(s.split())-1)//2)
      possible_replacement = []
      
      for i in range(0, len(candidate_synonym)):
        if (candidate_synonym[i].first_word == can_be_replaced_list[index] or candidate_synonym[i].second_word == can_be_replaced_list[index]):
          possible_replacement.append(candidate_synonym[i])
              
              
      random_candidate = return_random_number(0, len(possible_replacement)-1)
      
      original_word = ''
      new_word = ''
      if (possible_replacement[random_candidate].first_word == can_be_replaced_list[index]):
        original_word = possible_replacement[random_candidate].first_word
        new_word = possible_replacement[random_candidate].second_word
      elif (possible_replacement[random_candidate].second_word == can_be_replaced_list[index]):
        original_word = possible_replacement[random_candidate].second_word
        new_word = possible_replacement[random_candidate].first_word
          
      # print(original_word, 'is replaced by', new_word)
      
      perturbed_sample_tokenized = nltk.word_tokenize(perturbed_sample)
      replacement_position = -1
      for i in range(0, len(perturbed_sample_tokenized)):
        if (original_word == perturbed_sample_tokenized[i]):
          replacement_position = i
              
      if (replacement_position > -1):
        perturbed_sample = ""
        for i in range(0, replacement_position):
          perturbed_sample += perturbed_sample_tokenized[i] + ' '
        perturbed_sample += new_word + ' '
        for i in range(replacement_position+1, len(perturbed_sample_tokenized)):
          perturbed_sample += perturbed_sample_tokenized[i] + ' '
    
        word_replaced = True
        num_perturbed_words += 1
          
          
      # index += 1
          
  elif (len(candidate_synonym) == 0):
    print('No word was replaced.')

  
  if (word_replaced == True):
    is_sample_perturbed = True
    num_perturbed_samples += 1
  
  # print('Perturbed sample:', perturbed_sample)
  
  if (is_sample_perturbed == True):
    return perturbed_sample
      
    
    
      
      
print(sentence_pertube("films simply remade one bad film fails capture flavor terror 1963 film title liam neeson excellent always cast holds exception owen wilson bring right feel character luke major fault version strayed far shirley jackson story attempts grandiose lost thrill earlier film trade snazzier special effects say bad film enjoy friction terror older version much",0.1))


if __name__ == '__main__':
  pass

print(sentence_pertube("films simply remade one bad film fails capture flavor terror 1963 film title liam neeson excellent always cast holds exception owen wilson bring right feel character luke major fault version strayed far shirley jackson story attempts grandiose lost thrill earlier film trade snazzier special effects say bad film enjoy friction terror older version much",0.5))